---
title: "MODELAGEM PARA DADOS DE CONTAGEM"
author: "Hillnara de Paiva e João Vitor Andrade"
output: 
  rmdformats::material:
  html_document:
    code_folding: show
    highlight: textmate
    theme:
      bg: "#202123"
      fg: "#B8BCC2"
      primary: "#EA80FC"
      secondary: "#00DAC6"
      base_font:
        google: Prompt
      heading_font:
        google: Proza Libre
---

# MODELAGEM PARA DADOS DE CONTAGEM

## DESCRIÇÃO DO PROBLEMA

Os dados estão relacionados as postagem publicadas durante o ano de 2014 na página do Facebook. Este conjunto de dados contém 500 observações e 7 variáveis, são ela:

**PPDS:** Postagem por dia da semana

**ATP:** Alcance total da postagem

**TVP:** Total de visualizações da postagem

**UE:** Usuários engajados

**CP:** Consumidores de postagem

**PEP:** Pessoas ao longo da vida que gostaram do seu perfil e se envolveram com o sua postagem

**IT:** Interações totais

## RETIRADO DO SITE:

UCI - Machine Learning Repository <https://archive.ics.uci.edu/ml/datasets/CSM+%28Conventional+and+Social+Media+Movies%29+Dataset+2014+and+2015>

### PACOTES

```{r message=FALSE}
library(GLMsData) # Dataset MLG 
library(ISLR)     # Dataset livro: introduction a statistical learning 
library(MASS)     # Modelos residuais 
library(pscl)     # Calcular pseudo R2 
library(qqplotr)  # Gráfico
library(metan)
library(dbplyr)
library(dplyr)
library(ggplot2)
library(car)
library(AER)
library(lme4)
library(hnp)
library(knitr)
library(rsq)

```

### BANCO DE DADOS

```{r}

library(readxl)
dados <- read_excel("C:/Users/hilln/OneDrive/Área de Trabalho/MODELOS LINEARES GENERALIZADOS/UNIDADE 1/Apresentação1/Facebook.xls")
View(dados)
```

### OBJETIVO

Análisar o comportamento de uma variável dependente (Interações totais), em função da variáveis preditoras.

### GRÁFICO DE CORRELAÇÃO

```{r}
attach(dados)
dados %>%  
  corr_plot(PPDS, ATP, TVP, UE, CP, PEP,IT,
            shape.point = 19,
            size.point = 2,
            alpha.point = 0.5,
            alpha.diag = 0,
            pan.spacing = 0,
            col.sign = "gray",
            alpha.sign = 0.3,
            axis.labels = TRUE,
            progress = FALSE)

```

### MEDIDAS DESCRITIVAS

```{r}

kable(summary(dados))

```

### VARIÁVEL RESPOSTA

#### HISTOGRAMA

```{r}
hist(dados$IT) 
```

-   Os dados se concentram entorno de 0 e 1000
-   Uma distribuição assimetria positiva

#### GRÁFICO

```{r}
plot(dados$IT)
```

-   Gráfico de disperção

### MEDIA E DESVIO PADRÃO

```{r}
mean(dados$IT) 

sd(dados$IT) 
```

-   Desvio padrão mostra os valores do conjunto de dados IT que aparentemente estão aglomerados com proximidade uns dos outros.

#### BOX PLOT

```{r}
boxplot(dados$IT)
```

-   Os dados estão aglomerados, dado pelo intervalo interquartilíco (tamanho da caixa)
-   Dados são assimétricos positivos, pois a linha da mediana está proxima ao primeiro quartil.
-   Mediana menor que 500
-   Presença de Outlier, indicado pelos valores discrepantes.

# METODOLOGIA UTILIZADA

## MODELO POISSON

### AJUSTE DO MODELO PELA FUNÇÃO glm()

##### MODELO 1

```{r}
mod = glm( formula = IT ~ PPDS + ATP + TVP + UE + CP + PEP , data=dados,
           family=poisson(link="log"), control=list(trace=TRUE))
summary(mod)

```

### R2

```{r}
pR2(mod)
```

### ANÁLISE DE RESÍDUO

```{r}
hist( mod$residuals ) 
qqnorm(mod$residuals) 
qqline( mod$residuals, col = 'red' )
shapiro.test( mod$residuals )

cooksD = cooks.distance(mod) 
n <- nrow(dados)
plot(cooksD, main = "Cooks Distance for Influential Obs") 

abline(h = 4/n, lty = 2, col = "steelblue") # Adicionar linha de corte
```

# REMOVENDO DADOS INFLUENTES

```{r echo=FALSE}
influential_obs <- as.numeric(names(cooksD)[(cooksD > (4/n))]) 
dados_new <- dados[-influential_obs, ]
```

## NOVO AJUSTE COM DADOS SEM PONTOS INFLUENTES

#### MODELO 2

```{r}
mod2 = glm( formula = IT ~ PPDS + ATP + UE + CP + PEP , data = dados_new ,
           family = poisson(link = 'log'), control=list(trace=TRUE)) 
summary(mod2)
```

R2

```{r}
pR2(mod2)
```

## ANALISE DE RESIDUO

```{r}
hist( mod2$residuals ) 
qqnorm(mod2$residuals)
qqline( mod2$residuals, col = 'red' ) 
shapiro.test( mod2$residuals ) 

cooksD = cooks.distance(mod2) 
n <- nrow(dados_new)
plot(cooksD, main = "Cooks Distance for Influential Obs")
abline(h = 4/n, lty = 2, col = "steelblue") # Adicionar linha de corte
```

# REMOVENDO DADOS INFLUENTES

#### MODELO 3

```{r echo=FALSE}
influential_obs <- as.numeric(names(cooksD)[(cooksD > (4/n))])
```

## NOVO AJUSTE COM DADOS SEM PONTOS INFLUENTES

```{r}
dados_new1 <- dados_new[-influential_obs, ]

mod3 = glm( formula = IT ~ UE + CP + PEP , data = dados_new1 ,
           family = poisson(link = 'log') ,control=list(trace=TRUE)) 
summary(mod3)
```

R2

```{r}
pR2(mod3)
```

### ANÁLISE DE RESÍDUO

```{r}
hist( mod3$residuals ) 
qqnorm(mod3$residuals)
qqline( mod3$residuals, col = 'red' )
shapiro.test( mod3$residuals ) 
acf(mod3$residuals) 
plot(cooks.distance(mod3))

plot(dados_new1$IT, mod3$fitted.values )
```

ANALISANDO AS VARIÁVEIS SIGNIFICATIVAS

```{r}
drop1(mod3, test = "Chi")
```

# COMPARANDO OS MODELOS

```{r}
Ajuste = c("Modelo ","Modelo 2","Modelo 3")
AIC = c(AIC(mod),AIC(mod2),AIC(mod3))
Deviance = c(deviance(mod),deviance(mod2),deviance(mod3))
Pseudo_R2 =c(rsq(mod),rsq(mod2),rsq(mod3))
kable(data.frame(Ajuste, AIC, Deviance, Pseudo_R2))
```
